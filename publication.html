
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Patrick H. Chen | Publications</title>
<meta name="description" content="Patrick HP">


<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<!-- 
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
 -->

<link rel="stylesheet" href="main.css">

<link rel="canonical" href="publication.html">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-154898229-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-154898229-1');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="index.html">
       Patrick H. Chen 
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="index.html">
              About
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="publication.html">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h2 class="post-title"><b>Publications</b></h2>
    <p class="post-description"></p>
  </header>

  <article>
    <p>* below denotes equal contribution</p>
<div class="publications">


<!--  <h2 class="year">2021</h2> -->
  <ol class="bibliography"><li><div class="row">

</div>
</li></ol>


  <!-- <div class="col-sm-2 abbr">
  
  </div> -->



  <h2>Fast Machine Learning Inference</h2>
  <hr/>
  <br/>

  <h2>Machine Learning Model Compression</h2>
  <hr/>
  <br/>


  <ol class="bibliography"><li><div class="row">

      <div class="title">MulCode: A Multiplicative Multi-way Model for Compressing Neural Language Model</div>
      <div class="author">
                Yukon, Ma*
                <em>Patrick H. Chen*</em>,  
                and Cho-jui, Hsieh
      </div>
      <div class="periodical">
      
        <em>In Conference on Empirical Methods in Natural Language Processing</em>
          
        (<b>EMNLP</b>),
      
      
        2019
      </div>
        
    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      <!--[<a href="https://ieeexplore.ieee.org/iel7/4234/5534602/08624521.pdf" target="_blank">PDF</a>] -->
      [<a href="https://aclanthology.org/D19-1529.pdf" target="_blank">PDF</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
    <p>
It is challenging to deploy deep neural nets on
memory-constrained devices due to the explosion of numbers of parameters. Especially, the
input embedding layer and Softmax layer usually dominate the memory usage in an RNNbased language model. For example, input
embedding and Softmax matrices in IWSLT2014 German-to-English data set account for
more than 80% of the total model parameters. To compress these embedding layers, we
propose MulCode, a novel multi-way multiplicative neural compressor. MulCode learns
an adaptively created matrix and its multiplicative compositions. Together with a prior
weighted loss, MulCode is more effective than
the state-of-the-art compression methods. On
the IWSLT-2014 machine translation data set,
MulCode achieved 17 times compression rate
for the embedding and Softmax matrices, and
when combined with quantization technique,
our method can achieve 41.38 times compression rate with very little loss in performance.

</p>

    </div>
    
  </div>
      </div>
  </div>
  </li></ol>

  <ol class="bibliography"><li><div class="row">
  <div id="groupreduce18" class="col-sm-10">
    
      <div class="title">GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking</div>
      <div class="author">
        
                <em>Patrick H. Chen</em>,  
                Si Si,
                Yang Li,
                Ciprian Chelba
                and Cho-jui, Hsieh
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
          
        (<b>NeurIPS</b>),
      
      
        2018
        
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      <!--[<a href="https://ieeexplore.ieee.org/iel7/4234/5534602/08624521.pdf" target="_blank">PDF</a>] -->
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
    <p>
Model compression is essential for serving large deep neural nets on devices with
limited resources or applications that require real-time responses. As a case study, a
neural language model usually consists of one or more recurrent layers sandwiched
between an embedding layer used for representing input tokens and a softmax
layer for generating output tokens. For problems with a very large vocabulary
size, the embedding and the softmax matrices can account for more than half of
the model size. For instance, the bigLSTM model achieves great performance
on the One-Billion-Word (OBW) dataset with around 800k vocabulary, and its
word embedding and softmax matrices use more than 6GBytes space, and are
responsible for over 90% of the model parameters. In this paper, we propose
GroupReduce, a novel compression method for neural language models, based
on vocabulary-partition (block) based low-rank matrix approximation and the
inherent frequency distribution of tokens (the power-law distribution of words).
The experimental results show our method can significantly outperform traditional
compression methods such as low-rank approximation and pruning. On the OBW
dataset, our method achieved 6.6 times compression rate for the embedding and
softmax matrices, and when combined with quantization, our method can achieve
26 times compression rate, which translates to a factor of 12.8 times compression
for the entire model with very little degradation in perplexity.
</p>

    </div>
    
  </div>


</div>
</li></ol>




  <h2>Fundamental Machine Learning </h2>
  <hr/>
  <br/>


  <ol class="bibliography"><li><div class="row">
  <div id="groupreduce18" class="col-sm-10">
    
      <div class="title">Overcoming Catastrophic Forgetting by Bayesian Generative Regularization</div>
      <div class="author">
                <em>Patrick H. Chen</em>,  
                Wei Wei,
                Cho-jui, Hsieh,
                and Bo Dai
      </div>

      <div class="periodical">
      
        <em>In Conference of Machine Learning</em>
          
        (<b>ICML</b>),
      
      
        2021
        
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      <!--[<a href="https://ieeexplore.ieee.org/iel7/4234/5534602/08624521.pdf" target="_blank">PDF</a>] -->
    
      [<a href="http://proceedings.mlr.press/v139/chen21v/chen21v.pdf" target="_blank">PDF</a>]

     <!-- [<a href="https://github.com/ryoungj/optdom" target="_blank">Code</a>] -->
    </div>
    
    
    
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
    <p>
In this paper, we propose a new method to over-come catastrophic forgetting by adding generative regularization to Bayesian inference frame-work. Bayesian method provides a general frame-work for continual learning. We could further construct a generative regularization term for all given classification models by leveraging energy-based models and Langevin dynamic sampling to enrich the features learned in each task. By combining discriminative and generative loss together, we empirically show that the proposed method outperforms state-of-the-art methods on a variety of tasks, avoiding catastrophic forgetting in continual learning. In particular, the proposed method outperforms baseline methods over 15%on the Fashion-MNIST dataset and 10%on the CUB dataset.
</p>



    </div>
    
  </div>


</div>
</li></ol>





  <ol class="bibliography"><li><div class="row">
  <div id="groupreduce18" class="col-sm-10">
    
      <div class="title">Sign-OPT: A Query-Efficient Hard-label Adversarial Attack</div>
      <div class="author">
          Minhao Cheng1, Simranjit Singh1*, <em> Patrick H. Chen </em>, Pin-Yu Chen, Sijia Liu and Cho-Jui Hsieh
      </div>

      <div class="periodical">
      
        <em>In International Conference on Learning Representations</em>
          
        (<b>ICLR</b>),
      
        2020
        
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      <!--[<a href="https://ieeexplore.ieee.org/iel7/4234/5534602/08624521.pdf" target="_blank">PDF</a>] -->
    
      [<a href="https://arxiv.org/pdf/1909.10773.pdf" target="_blank">PDF</a>]

     <!-- [<a href="https://github.com/ryoungj/optdom" target="_blank">Code</a>] -->
    </div>
    
    
    
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
    <p>
We study the most practical problem setup for evaluating adversarial robustness
of a machine learning system with limited access: the hard-label black-box attack setting for generating adversarial examples, where limited model queries
are allowed and only the decision is provided to a queried data input. Several
algorithms have been proposed for this problem but they typically require huge
amount (>20,000) of queries for attacking one example. Among them, one of
the state-of-the-art approaches (Cheng et al., 2019) showed that hard-label attack
can be modeled as an optimization problem where the objective function can be
evaluated by binary search with additional model queries, thereby a zeroth order optimization algorithm can be applied. In this paper, we adopt the same optimization
formulation but propose to directly estimate the sign of gradient at any direction
instead of the gradient itself, which enjoys the benefit of single query. Using
this single query oracle for retrieving sign of directional derivative, we develop
a novel query-efficient Sign-OPT approach for hard-label black-box attack. We
provide a convergence analysis of the new algorithm and conduct experiments
on several models on MNIST, CIFAR-10 and ImageNet. We find that Sign-OPT
attack consistently requires 5× to 10× fewer queries when compared to the current
state-of-the-art approaches, and usually converges to an adversarial example with
smaller perturbation.
</p>



    </div>
    
  </div>


</div>
</li></ol>




</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container" style="text-align: center;">
    <!-- &copy; Copyright 2022 Yangjun  Ruan. -->
    
    
    
    Last updated: April 15, 2022.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="common.js"></script>


</html>

