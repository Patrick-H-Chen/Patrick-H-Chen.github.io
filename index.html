
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Patrick H. Chen</title>
<meta name="description" content="PHC homepage
">

<!-- Open Graph -->
<link rel="stylesheet" href="github-markdown.css">


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> 

<!-- Styles -->
 
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
 

 <link rel="stylesheet" href="main.css"> 

<link rel="canonical" href="index.html">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-154898229-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-154898229-1');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


		<style>
			.markdown-body {
				box-sizing: border-box;
				min-width: 200px;
				max-width: 980px;
				margin: 0 auto;
				padding: 45px;
			}
			@media (max-width: 767px) {
				.markdown-body {
					padding: 15px;
				}
				.left {
			    width: 100%;
			  }
			  .right {
			    width: 100%;
			  }
				.portrait {
					margin-bottom: 1em;
			  }
				.column-third {
					float: left;
			    width: 100%;
			  }
			}
			html {
			  width: 100vw;
			}
			body {
			  overflow-x: hidden;
			}
		</style>



  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="index.html">
       Patrick H. Chen
      </a>
      
      
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="index.html">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="publication.html">
                Publications
                
              </a>
          </li>
          
          
          <li class="nav-item ">
              <a class="nav-link" href="schedule.html">
                Schedule
                
              </a>
          </li>
          
        </ul>
      </div>
    </div>
  </nav>

</header>






    <!-- Content -->


    <div class="container mt-5">
			<!-- <h2>Home &nbsp; &nbsp; <a href="./pubs/index.html">Publications</a></h2> -->
		        <h1>Patrick H. Chen</h1>
	 		<div class="row markdown-body">
				<div class="column-picture left">
		 			<img class="portrait-circular" src="pic/Patrick.jpg">
				</div>
				<div class="column-picture right">
					<p>Assistant Professor <br/>
					Dept. of Computer Science<br/>
					Binhamton University</p>

					<p>patrickchen [at] binghamton [dot] edu</p>
<!--
					<p>
						<a href="./pubs/index.html">Publications</a>, <a href="https://scholar.google.com/citations?user=WjCG3owAAAAJ&hl=en">Google Scholar</a>, <a href="./bio.html">Biography</a>
					</p>
-->
				</div>
			</div>





      <div class="post">


  <header class="post-header">
    
    
  </header>

  <article>
    <br/>
    <br/>
    <div class="clearfix">
      <h2 id="bio">Bio</h2>
<hr />
<p>I am an Assistant Professor in Computer Science at Binghamton University, leading the <b>FUEL</b> lab. I obtained my Ph.D. from UCLA, supervised by <a href="http://web.cs.ucla.edu/~chohsieh/index.html#about">Cho-Jui Hsieh</a>. I obtained my Bachelor's degree in Electrical Engineering and History from National Taiwan University. Before starting my Ph.D. journey, I worked with <a href="https://sites.google.com/site/shenshyang/home">Shen-Shyang Ho</a> as a Research Assistant at Nanyang Technological University. Before joining Binghamton University, I worked as a Research Scientist at ASAPP.</p>

<p><br /></p>


                        <h2>Research</h2>
<hr />

            <p> My research aspiration is to add <span font-weigh='bolder't>FUEL</span> to machine learning!! I aim to work on <b>F</b>undamental, <b>U</b>ncertainty, and <b>E</b>fficiency aspects of <b>L</b>earning! To make models reliably applicable, we studied the fundamental aspects of ML, such as factualness and robustness, and analyzed uncertainty issues in various applications. To make models more efficient for practical usage, I focused on 1) compressing machine learning models to make them deployable on devices with limited memory and 2) accelerating the training and inference time of machine learning models to meet latency requirements.
</p>

<!--
					<p><b>Representation learning</b> &nbsp;&nbsp;&nbsp;&nbsp; How we represent data affects how effectively we process and understand it. I am interested in learning useful and robust representations, with a particular interest in techniques that learn representations from pretext tasks. In recent work, we showed how to <a href="https://arxiv.org/abs/2106.10800">learn compressed representations of data</a> with performance guarantees on a large, possibly infinite, set of downstream tasks.
					</p>
					<p>
					<b>Learning with discrete structure</b> &nbsp;&nbsp;&nbsp;&nbsp; I am also motivated by applications to reasoning about data with discrete structure, such as integer programming or discrete reasoning tasks. Together with colleagues, we built the first artificial agent that plays the <a href="https://www.nature.com/articles/nature16961">board game Go at a superhuman level</a>, developed structured models of human-written <a href="http://proceedings.mlr.press/v32/maddison14.html">source code</a>, and designed <a href="https://arxiv.org/abs/2006.08063">relaxed gradient estimators</a> for models with structured latent variables.
					</p>
					<p>
					<b>Inference and optimization</b> &nbsp;&nbsp;&nbsp;&nbsp; Algorithms for Bayesian inference and optimization are the engines that drive machine learning. Although these two problems seem distinct, they have a lot of shared structure. I am interested in this interplay: we showed how to simulate from a probability distribution by <a href="https://papers.nips.cc/paper/5449-a-sampling">optimizing a random function</a> and how the use of <a href="https://epubs.siam.org/doi/abs/10.1137/19M130858X">a kinetic energy can condition optimization</a>.
					</p>




-->

<h4 id="selected-publications-full-list"><strong>Selected Publications</strong> <a href="publication.html">[Full List]</a></h4>
<hr />

<div class="publications">


  <ol class="bibliography"><li><div class="row">
  <div id="drone21" class="col-sm-10">
      <div class="title">DRONE: Data-aware Low-rank Compression for Large NLP Models</div>
      <div class="author">
                <em>Patrick H. Chen</em>,  
                Hsiang-fu Yu,
                Inderjit S. Dhillon,
                and Cho-jui, Hsieh
      </div>
      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
          
        (<b>NeurIPS</b>),
      
        2021
      </div>
        
    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      [<a href="https://proceedings.neurips.cc/paper/2021/file/f56de5ef149cf0aedcc8f4797031e229-Paper.pdf" ftarget="_blank">PDF</a>]
    
    </div>

    <div class="abstract hidden">
    <p>
The representations learned by large-scale NLP models such as BERT have been
widely used in various tasks. However, the increasing model size of the pre-trained
models also brings efficiency challenges, including inference speed and model
size when deploying models on mobile devices. Specifically, most operations
in BERT consist of matrix multiplications. These matrices are not low-rank and
thus canonical matrix decompositions do not lead to efficient approximations. In
this paper, we observe that the learned representation of each layer lies in a low-dimensional space. Based on this observation, we propose DRONE (data-aware
low-rank compression), a provably optimal low-rank decomposition of weight
matrices, which has a simple closed form solution that can be efficiently computed.
DRONE can be applied to both fully-connected and self-attention layers appearing
in the BERT model. In addition to compressing standard models, our method
can also be used on distilled BERT models to further improve the compression
rate. Experimental results show that DRONE is able to improve both model size
and inference speed with limited loss in accuracy. Specifically, DRONE alone
achieves 1.92x speedup on the MRPC task with only 1.5% loss in accuracy, and
when DRONE is combined with distillation, it further achieves over 12.3x speedup
on various natural language inference tasks.
</p>

    </div>


   </div> 

</div>
</li></ol>

  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div> -->



  <div id="groupreduce18" class="col-sm-10">
    
      <div class="title">GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking</div>
      <div class="author">
        
                <em>Patrick H. Chen</em>,  
                Si Si,
                Yang Li,
                Ciprian Chelba
                and Cho-jui, Hsieh
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
          
        (<b>NeurIPS</b>),
      
      
        2018
        
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      [<a href="https://proceedings.neurips.cc/paper/2018/file/a2b8a85a29b2d64ad6f47275bf1360c6-Paper.pdf" target="_blank">PDF</a>] 
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
    <p>
Model compression is essential for serving large deep neural nets on devices with
limited resources or applications that require real-time responses. As a case study, a
neural language model usually consists of one or more recurrent layers sandwiched
between an embedding layer used for representing input tokens and a softmax
layer for generating output tokens. For problems with a very large vocabulary
size, the embedding and the softmax matrices can account for more than half of
the model size. For instance, the bigLSTM model achieves great performance
on the One-Billion-Word (OBW) dataset with around 800k vocabulary, and its
word embedding and softmax matrices use more than 6GBytes space, and are
responsible for over 90% of the model parameters. In this paper, we propose
GroupReduce, a novel compression method for neural language models, based
on vocabulary-partition (block) based low-rank matrix approximation and the
inherent frequency distribution of tokens (the power-law distribution of words).
The experimental results show our method can significantly outperform traditional
compression methods such as low-rank approximation and pruning. On the OBW


</p>

    </div>
    
  </div>

</div>
</li></ol>



  <ol class="bibliography"><li><div class="row">
  <div id="forgetting21" class="col-sm-10">
    
      <div class="title">Overcoming Catastrophic Forgetting by Bayesian Generative Regularization</div>
      <div class="author">
                <em>Patrick H. Chen</em>,  
                Wei Wei,
                Cho-jui, Hsieh,
                and Bo Dai
      </div>

      <div class="periodical">
      
        <em>In Conference of Machine Learning</em>
          
        (<b>ICML</b>),
      
      
        2021
        
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
      <!--[<a href="https://ieeexplore.ieee.org/iel7/4234/5534602/08624521.pdf" target="_blank">PDF</a>] -->
    
      [<a href="http://proceedings.mlr.press/v139/chen21v/chen21v.pdf" target="_blank">PDF</a>]

     <!-- [<a href="https://github.com/ryoungj/optdom" target="_blank">Code</a>] -->
    </div>
    
    
    
    

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
    <p>
In this paper, we propose a new method to over-come catastrophic forgetting by adding generative regularization to Bayesian inference frame-work. Bayesian method provides a general frame-work for continual learning. We could further construct a generative regularization term for all given classification models by leveraging energy-based models and Langevin dynamic sampling to enrich the features learned in each task. By combining discriminative and generative loss together, we empirically show that the proposed method outperforms state-of-the-art methods on a variety of tasks, avoiding catastrophic forgetting in continual learning. In particular, the proposed method outperforms baseline methods over 15%on the Fashion-MNIST dataset and 10%on the CUB dataset.
</p>



    </div>
    
  </div>






</div>
</li></ol>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container" style="text-align: center;">
    <!-- &copy; Copyright 2022 Yangjun  Ruan. -->
    
    
    
    Last updated: Jan 1, 2024.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="common.js"></script>


</html>

