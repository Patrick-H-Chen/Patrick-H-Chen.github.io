
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Yangjun  Ruan</title>
<meta name="description" content="Yangjun's homepage
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<!-- 
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
 -->

<link rel="stylesheet" href="main.css">

<link rel="canonical" href="index.html">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-154898229-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-154898229-1');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="index.html">
       Yangjun   Ruan 
      </a>
      
      
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="index.html">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="publication.html">
                Publications
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>




		<h1>Chris J. Maddison</h1>
			<!-- <h2>Home &nbsp; &nbsp; <a href="./pubs/index.html">Publications</a></h2> -->

	 		<div class="row">
				<div class="column-picture left">
		 			<img class="portrait-circular" src="pic/PC.png">
				</div>
				<div class="column-picture right">
					<p>Assistant Professor<br/>
					Dept. of Computer Science and Dept. of Statistical Sciences<br/>
					University of Toronto</p>

					<p>CIFAR AI Chair, Vector Institute<br/>
						Research Scientist, DeepMind</p>

					<p>cmaddis [at] cs [dot] toronto [dot] edu</p>

					<p>
						<a href="./pubs/index.html">Publications</a>, <a href="https://scholar.google.com/citations?user=WjCG3owAAAAJ&hl=en">Google Scholar</a>, <a href="./bio.html">Biography</a>
					</p>
				</div>
			</div>

    <!-- Content -->


    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="pic/PC.png" >
      
      
    </div>
    
 
    <h2 class="post-title">
     <span class="font-weight-bold">Yangjun  Ruan</span>
    </h2>
    <p class="desc" >Ph.D. Candidate, Computer Science<br/> <a href="http://learning.cs.toronto.edu/" target="_blank">Machine Learning Group</a><br/> <a href="https://web.cs.toronto.edu/" target="_blank">University of Toronto</a> &   <a href="https://vectorinstitute.ai/" target="_blank">Vector Institute</a><br/> <br/> Email&#58; yjruan [at] cs [dot] toronto [dot] edu</p>
    
     
    <h1 class="about social" style="text-align:left">
      

<a href="https://scholar.google.com/citations?user=9AdCSywAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/ryoungj" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>

<a href="https://twitter.com/YangjunR" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>








<a href="assets/pdf/CV_Yangjun_Ruan.pdf" target="_blank" title="Vitae"><i class="ai ai-cv"></i></a>

    </h1>
    
  </header>

  <article>
    <br/>
    <br/>
    <div class="clearfix">
      <h4 id="bio"><strong>Bio</strong></h4>
<hr />
<p>I am a Ph.D. student in Computer Science at <a href="https://web.cs.toronto.edu/">University of Toronto</a>, supervised by <a href="http://www.cs.toronto.edu/~cmaddis/">Chris Maddison</a>. Previously, I obtained my Bachelor degree in Information Engineering from <a href="http://www.zju.edu.cn/english/">Zhejiang University</a> in July 2020. In summer 2019, I was a visiting student at <a href="https://www.cs.ucla.edu/">UCLA</a>, where I worked with <a href="http://web.cs.ucla.edu/~chohsieh/index.html#about">Cho-Jui Hsieh</a>.</p>

<p>I’m currently working on the intersection of machine learning and information theory, with a focus on representation learning, domain generalization, and neural compression. 
In particular, I want to understand how to learn useful and trustworthy representations from data, and motivate more efficient and principled representation learning methods.
I’m also interested in implicit deep learning and generative modeling.</p>

<p><br /></p>
<h4 id="selected-publications-full-list"><strong>Selected Publications</strong> <a href="publication.html">[Full List]</a></h4>
<hr />
<p>* below denotes equal contribution</p>
<div class="publications">
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div> -->

  <div id="ruan2022optdom" class="col-sm-10">
    
      <div class="title">Optimal Representations for Covariate Shift</div>
      <div class="author">
        
        
        
          

          
          
          
          

          
          
          
            
              
                <em>Yangjun Ruan*</em>,  
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Yann Dubois*,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  and Chris J Maddison
                
              
            
          
        
      </div>

      <div class="periodical">
      
          
            <em>In International Conference on Learning Representations</em>
          
        (<b>ICLR</b>),
      
      
        2022
      
      
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
    
    
    
    
      
      [<a href="https://arxiv.org/pdf/2201.00057.pdf" target="_blank">PDF</a>]
      
    
    
    
    
      [<a href="https://github.com/ryoungj/optdom" target="_blank">Code</a>]
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Machine learning systems often experience a distribution shift between training and testing. In this paper, we introduce a simple variational objective whose optima are \textitexactly the set of \textitall representations on which risk minimizers are guaranteed to be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate shifts. Our objective has two components. First, a representation must remain discriminative for the task, i.e., some predictor must be able to simultaneously minimize the source and target risk. Second, the representation’s marginal support needs to be the same across source and target. We make this practical by designing self-supervised learning methods that only use unlabelled data and augmentations to train robust representations. Our objectives achieve state-of-the-art results on DomainBed, and give insights into the robustness of recent methods, such as CLIP.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div> -->

  <div id="ruan2021mcbits" class="col-sm-10">
    
      <div class="title">Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding</div>
      <div class="author">
        
        
        
          

          
          
          
          

          
          
          
            
              
                <em>Yangjun Ruan*</em>,  
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Karen Ullrich*,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Daniel Severo*,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  James Townsend,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Ashish Khisti,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Arnaud Doucet,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Alireza Makhzani,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  and Chris J Maddison
                
              
            
          
        
      </div>

      <div class="periodical">
      
          
            <em>In International Conference on Machine Learning</em>
          
        (<b>ICML</b>),
      
      
        2021
      
      
        <b style="color:#B71C1C;">[Long talk]</b>
      
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
    
    
    
    
      
      [<a href="https://arxiv.org/pdf/2102.11086.pdf" target="_blank">PDF</a>]
      
    
    
    
    
      [<a href="https://github.com/ryoungj/mcbits" target="_blank">Code</a>]
    
    
      
      [<a href="/~yjruan/assets/pdf/poster/McBits_poster.pdf" target="_blank">Poster</a>]
      
    
    
      
      [<a href="/~yjruan/assets/pdf/slides/McBits_slides.pdf" target="_blank">Slides</a>]
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Latent variable models have been successfully applied in lossless compression with the bits-back coding algorithm. However, bits-back suffers from an increase in the bitrate equal to the KL divergence between the approximate posterior and the true posterior. In this paper, we show how to remove this gap asymptotically by deriving bits-back coding algorithms from tighter variational bounds. The key idea is to exploit extended space representations of Monte Carlo estimators of the marginal likelihood. Naively applied, our schemes would require more initial bits than the standard bits-back coder, but we show how to drastically reduce this additional cost with couplings in the latent space. When parallel architectures can be exploited, our coders can achieve better rates than bits-back with little additional cost. We demonstrate improved lossless compression rates in a variety of settings, especially in out-of-distribution or sequential data compression.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div> -->

  <div id="ruan2020zol2l" class="col-sm-10">
    
      <div class="title">Learning to Learn by Zeroth-Order Oracle</div>
      <div class="author">
        
        
        
          

          
          
          
          

          
          
          
            
              
                <em>Yangjun Ruan</em>,  
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Yuanhao Xiong,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Sashank Reddi,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  Sanjiv Kumar,
                
              
            
          
        
          

          
          
          
          

          
          
          
            
              
                
                  and Cho-Jui Hsieh
                
              
            
          
        
      </div>

      <div class="periodical">
      
          
            <em>In International Conference on Learning Representations</em>
          
        (<b>ICLR</b>),
      
      
        2020
      
      
      </div>
    

    <div class="links">
    
      [<a class="abstract button" role="button">Abstract</a>]
    
    
    
    
      
      [<a href="https://openreview.net/pdf?id=ryxz8CVYDH" target="_blank">PDF</a>]
      
    
    
    
    
      [<a href="https://github.com/ryoungj/ZO-L2L" target="_blank">Code</a>]
    
    
    
      
      [<a href="/~yjruan/assets/pdf/slides/ZO-L2L_slides.pdf" target="_blank">Slides</a>]
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the learning to learn (L2L) framework, we cast the design of optimization algorithms as a machine learning problem and use deep neural networks to learn the update rules. In this paper, we extend the L2L framework to zeroth-order (ZO) optimization setting, where no explicit gradient information is available. Our learned optimizer, modeled as recurrent neural network (RNN), first approximates gradient by ZO gradient estimator and then produces parameter update utilizing the knowledge of previous iterations. To reduce high variance effect due to ZO gradient estimator, we further introduce another RNN to learn the Gaussian sampling rule and dynamically guide the query direction sampling. Our learned optimizer outperforms hand-designed algorithms in terms of convergence rate and final solution on both synthetic and practical ZO optimization tasks (in particular, the black-box adversarial attack task, which is one of the most widely used tasks of ZO optimization). We finally conduct extensive analytical experiments to demonstrate the effectiveness of our proposed optimizer.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

<p><br /></p>
<h4 id="services"><strong>Services</strong></h4>
<hr />
<ul>
  <li>Conference reviewer: NeurIPS (2020, 2021), ICLR (2021, 2022), ICML (2021)</li>
  <li>Workshop reviewer: NeurIPS DGMs Applications Workshop (2021)</li>
</ul>

<p><br /></p>
<h4 id="selected-awards--honors"><strong>Selected Awards &amp; Honors</strong></h4>
<hr />
<ul>
  <li>DiDi Gruduate Student Award, 2021</li>
  <li>Computer Science 50th Anniversary Graduate Scholarship, 2020.</li>
  <li>CHU Kochen Scholarship (highest honor at Zhejiang University), 2019.</li>
  <li>Top 10 students at Zhejiang University, 2019.</li>
  <li>Cross-disciplinary Scholars in Science and Technology (CSST), UCLA, 2019.</li>
  <li>National Scholarship (top 1.5%), 2017, 2018, 2019.</li>
  <li>Meritorious Winner, Interdisciplinary Contest in Modeling (ICM), 2018.</li>
</ul>

    </div>

    

    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container" style="text-align: center;">
    <!-- &copy; Copyright 2022 Yangjun  Ruan. -->
    
    
    
    Last updated: February 23, 2022.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="common.js"></script>


</html>

